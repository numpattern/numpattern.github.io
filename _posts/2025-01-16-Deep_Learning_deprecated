---
layout: post
title: Deep Learning
tags: [AI]
bigimg: /img/per010rz.jpg
share-img: /img/abstract_bg_cuda.png.PNG
---


The scale control progress in deep learning algorithms. Practitioner skills may be determinant in cases with small training sets, however cases with more data make it clearer about the performance. Data, computation and improvements of algorithms create progress. Training neural nets is an iterative process that starts from landing and idea, code it and run experiments. If it takes long, 
it delays progress.

There is a prerogative by Geoffrey Hinton is that there must be some biological version of back proprogration in the brain that allows learning.

Back-propagation
