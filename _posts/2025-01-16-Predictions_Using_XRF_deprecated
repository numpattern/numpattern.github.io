---
layout: post
title: Prediction Models Using XRF
#subtitle: An essential part of Resources Evaluation. GSLIB Cell Based Method.
tags: [XRF, Regressions]
bigimg: /img/per010rz.jpg
share-img: /img/abstract_bg_cuda.png.PNG
---

Regression Models can be built to predict target values based on XRF data. In mining, thousands of meters get scanned. The reference data are the assays obtained from multiple laboratories. The XRF data is subject to a variety of post processing to be in good shape for calibration. The detector determines the resolution in the number of keV channels. There are several factors that affect the resultant XRF data obtained in the collector. 

There is a support difference between the target assay values for a specific interval and the number of XRF shots. The XRF head must be close enough to the surface being hit to minimize the noise in the output signal. A regression model can be built once all previous considerations have been addressed.

The target assays have some limitations. Depending on the assaying technique, the upper and lower detection limits must be considered. 

Several techniques can be applied to obtain the results. Linear Regression. Power Models and machine learning techniques. XRF data on rock usually target a support different than the scale of the assays. Depending on the support required for predictions. The assays must be downscaled to XRF scale or the XRF data upscaled to assays scale. 

Is is important to understand the nature of the data. A linear model can be a best fit in some cases, while some others like Power Model ca be better for other cases. For XRF this all relates to what are the peaks selected.

I must clarify that for regression, we must decide if using 1 or many channels is the way to go. xrf data usually has many channels. Best features are selected using different techniques, however this may not be an appealing way to do it, considering that we should know the theoretical channels in advance and possibly every possible park for the artifacts like sum or escape peak for specific elements.


Deciding wether a model is best or not is a complex question. Does adding more data help to the model or does it make things worse. A good approach is t add validation metrics. Track the validation metrics such as RMSE, MSE vs adding more training data. If the RMSE does not improve or even get worse then it's time to stop. 

A common question is when to stop increasing the training data. Plot a learning curve to show the training and validation performance as a function of the training set size. The point where the validation performance curve starts to flatten is the point of diminishing returns. If the increments of data come in chunks: incomes by country or intervals within drillholes, a simple approach is to  


## Comments on using Ransac for Outlier Detection
In general, outliers should be managed before fitting a regression model. If this is not the case, methods such as Gaussian Mixture Models, Ransac, and others treat as outliers to any poorly fitted predictions. This performance-focused approach does not grasp the nature of the variable. This post contains comments on Ransac.

RANSACRegressor from sklearn allows to create a regression model and detect outliers. Ransac's primary goal is to achieve a robust fit by trimming out data. It iteratively fits models to random subsets of the data and identifies inliers based on a residual threshold. RANSAC's outlier detection relies on random sampling, which means the outliers can vary between runs, causing variability in the models. For specific contexts, RANSAC can be complemented with probability plots for outlier management.

It's concerning seeing practitioners to optimize RANSACRegressor to a performance metric varying residual_thresholds. This must be avoided as inlier_ratio will change accordingly. RANSAC might seem appealing for its convenience, however it misguides users to correctly analyze extreme values. Outlier management must be done carefully. If Ransac's use cannot be avoided, workaround the randomness in Ransac and use the residuals to obtain a target set of outliers. Some even tried to force Ransac to target inlier ratios.





